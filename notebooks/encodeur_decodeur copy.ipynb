{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-09T17:40:53.789496Z",
     "iopub.status.busy": "2025-01-09T17:40:53.789146Z",
     "iopub.status.idle": "2025-01-09T17:40:57.998055Z",
     "shell.execute_reply": "2025-01-09T17:40:57.997320Z",
     "shell.execute_reply.started": "2025-01-09T17:40:53.789473Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ids/meladlouni/miniconda3/envs/nlp_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from rouge_score import rouge_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM \n",
    "import torch\n",
    "import warnings\n",
    "# Disable all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:41:04.488643Z",
     "iopub.status.busy": "2025-01-09T17:41:04.488332Z",
     "iopub.status.idle": "2025-01-09T17:41:04.582466Z",
     "shell.execute_reply": "2025-01-09T17:41:04.581619Z",
     "shell.execute_reply.started": "2025-01-09T17:41:04.488607Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device globally\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Set-up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T18:48:44.090746Z",
     "iopub.status.busy": "2025-01-09T18:48:44.090408Z",
     "iopub.status.idle": "2025-01-09T18:48:46.772464Z",
     "shell.execute_reply": "2025-01-09T18:48:46.771756Z",
     "shell.execute_reply.started": "2025-01-09T18:48:44.090720Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In OBS:\n",
      "Only in x : \u001b[91m0\u001b[0m -> non-used\n",
      "Only in y : \u001b[91m27\u001b[0m -> non-used\n",
      "In both : \u001b[92m402\u001b[0m\n",
      "\n",
      "In RCT:\n",
      "Only in x : \u001b[91m11\u001b[0m -> non-used\n",
      "Only in y : \u001b[91m8\u001b[0m -> non-used\n",
      "In both : \u001b[92m370\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/ids/meladlouni/projects/nlp_project/data/train\"\n",
    "data_obs = extract_data(path, \"OBS\")\n",
    "data_rct = extract_data(path, \"RCT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T18:48:47.379021Z",
     "iopub.status.busy": "2025-01-09T18:48:47.378699Z",
     "iopub.status.idle": "2025-01-09T18:48:47.434907Z",
     "shell.execute_reply": "2025-01-09T18:48:47.434003Z",
     "shell.execute_reply.started": "2025-01-09T18:48:47.378994Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /home/ids/meladlouni/projects/nlp_project/data/train_data.dat\n"
     ]
    }
   ],
   "source": [
    "# Change the path to a writable directory\n",
    "output_path = \"/home/ids/meladlouni/projects/nlp_project/data/train_data.dat\"\n",
    "\n",
    "# Save the data\n",
    "with open(output_path, \"wb\") as f:\n",
    "    pkl.dump([data_obs, data_rct], f)\n",
    "\n",
    "print(f\"Data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:41:14.119472Z",
     "iopub.status.busy": "2025-01-09T17:41:14.119197Z",
     "iopub.status.idle": "2025-01-09T17:41:14.165268Z",
     "shell.execute_reply": "2025-01-09T17:41:14.164642Z",
     "shell.execute_reply.started": "2025-01-09T17:41:14.119451Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37432520</td>\n",
       "      <td>Introduction \\n\\nSepsis is a common cause of c...</td>\n",
       "      <td>PURPOSE: The Acute Disease Quality Initiative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            article  \\\n",
       "count        402                                                402   \n",
       "unique       402                                                402   \n",
       "top     37432520  Introduction \\n\\nSepsis is a common cause of c...   \n",
       "freq           1                                                  1   \n",
       "\n",
       "                                                 abstract  \n",
       "count                                                 402  \n",
       "unique                                                402  \n",
       "top     PURPOSE: The Acute Disease Quality Initiative ...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle encodeur-décodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Les modèles Transformers de type encodeur-décodeur, tels que BART, T5, et Pegasus, sont particulièrement bien adaptés à notre projet de génération de résumés d’articles médicaux. Ces modèles, après avoir été pré-entraînés sur de vastes corpus textuels, ont été spécifiquement fine-tunés pour des tâches de **summarization**.\n",
    "\n",
    "### Comment fonctionnent les modèles encodeurs-décodeurs ?\n",
    "Un modèle encodeur-décodeur repose sur deux composants principaux :  \n",
    "1. **L'encodeur** : Il lit le texte d'entrée (le corps de l'article) et le transforme en une représentation dense appelée embedding ou vecteur d'encodage. Ce vecteur capture les relations sémantiques et contextuelles de chaque mot ou phrase dans le texte.  \n",
    "2. **Le décodeur** : À partir du vecteur d'encodage, le décodeur génère mot par mot le texte de sortie (le résumé). À chaque étape, il utilise à la fois le contexte global du texte source et les mots précédemment générés.  \n",
    "\n",
    "Le mécanisme clé qui rend ces modèles performants est **l’attention croisée** (notamment l’attention multi-têtes), qui permet au modèle de se concentrer sur les parties les plus pertinentes du texte source à chaque étape de la génération.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Division des articles en segments avec chevauchement**\n",
    "\n",
    "Dans le cadre de notre projet, les articles scientifiques contiennent un grand nombre de mots ou de tokens, dépassant souvent la capacité maximale que le modèle peut traiter en une seule fois (généralement 512 ou 1024 tokens pour les modèles comme BART). Afin de permettre au modèle d’analyser efficacement ces longs textes, il est nécessaire de diviser les articles en segments (ou chunks) de taille gérable.\n",
    "\n",
    "La fonction suivante, `split_into_chunks_with_overlap`, a pour objectif de :\n",
    "1. **Diviser les articles longs en morceaux** : Chaque segment respecte une limite maximale de tokens définie par le paramètre `chunk_size`.\n",
    "2. **Ajouter un chevauchement entre les segments** : Les segments successifs partagent un certain nombre de tokens définis par `overlap_size`. Cela permet au modèle de mieux comprendre les transitions et les connexions entre les parties d’un article, en évitant de perdre des informations importantes à la frontière entre deux segments.\n",
    "\n",
    "### Paramètres importants :\n",
    "- `article` : L'article complet à découper.\n",
    "- `tokenizer` : Le tokenizer utilisé pour convertir le texte en tokens numériques, compatible avec le modèle pré-entraîné choisi.\n",
    "- `chunk_size` : La taille maximale (en tokens) d’un segment, par défaut 512.\n",
    "- `overlap_size` : Le nombre de tokens communs entre deux segments consécutifs, par défaut 100.\n",
    "\n",
    "### Résultat :\n",
    "La fonction retourne une liste de segments textuels prêts à être traités par le modèle. Chaque segment est encodé avec un chevauchement pour garantir la continuité du contexte lors de la génération des résumés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:41:17.859256Z",
     "iopub.status.busy": "2025-01-09T17:41:17.858999Z",
     "iopub.status.idle": "2025-01-09T17:41:17.864026Z",
     "shell.execute_reply": "2025-01-09T17:41:17.863153Z",
     "shell.execute_reply.started": "2025-01-09T17:41:17.859235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_into_chunks_with_overlap(article, tokenizer, chunk_size=512, overlap_size=100):\n",
    "    \"\"\"\n",
    "    Splits a long article into chunks with a specified size and overlap.\n",
    "\n",
    "    Args:\n",
    "        article (str): The full article to be summarized.\n",
    "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer to count tokens.\n",
    "        chunk_size (int): The maximum number of tokens per chunk (default: 512).\n",
    "        overlap_size (int): The number of tokens to overlap between chunks (default: 100).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of chunks (strings), each with a token length <= chunk_size, and overlap.\n",
    "    \"\"\"\n",
    "    # Tokenize the article into token IDs (flat list)\n",
    "    tokens = tokenizer(article, truncation=False, padding=False)[\"input_ids\"]\n",
    "\n",
    "    # Create chunks with overlap\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - overlap_size):\n",
    "        chunk = tokens[i:i + chunk_size]\n",
    "        chunk_text = tokenizer.decode(chunk, skip_special_tokens=True)\n",
    "        chunks.append(chunk_text)\n",
    "        \n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Génération des résumés pour chaque segment d'article**\n",
    "\n",
    "Une fois les articles divisés en segments (ou chunks) grâce à la fonction `split_into_chunks_with_overlap`, il devient nécessaire de générer un résumé pour chaque segment et de combiner ces résumés en un résumé final. C'est précisément le rôle de la fonction `generate_chunk_summaries`.\n",
    "\n",
    "### Paramètres importants :\n",
    "- `article` : Le texte complet de l'article à résumer.\n",
    "- `tokenizer` : Le tokenizer utilisé pour encoder les segments avant de les passer au modèle.\n",
    "- `model` : Le modèle pré-entraîné et fine-tuné pour la tâche de résumé automatique (par exemple, BART).\n",
    "- `device` : Le dispositif de calcul (par défaut, GPU si disponible).\n",
    "- `chunk_size` : La taille maximale (en tokens) des segments. Cette valeur doit correspondre à la limite du modèle.\n",
    "- `overlap_size` : Le nombre de tokens partagés entre les segments consécutifs, pour garantir une continuité contextuelle.\n",
    "- `min_length` et `max_length` : Contraintes sur la longueur des résumés générés pour chaque segment.\n",
    "- `length_penalty` : Un hyperparamètre influençant la longueur des résumés générés. Une valeur plus élevée pénalise les résumés trop longs.\n",
    "\n",
    "### Résultat :\n",
    "La fonction retourne un **résumé final combiné** pour l'article complet. Chaque segment étant résumé indépendamment, cette approche permet au modèle de traiter des articles longs tout en produisant des résumés informatifs et cohérents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:26:17.702899Z",
     "iopub.status.busy": "2025-01-09T20:26:17.702527Z",
     "iopub.status.idle": "2025-01-09T20:26:17.708461Z",
     "shell.execute_reply": "2025-01-09T20:26:17.707648Z",
     "shell.execute_reply.started": "2025-01-09T20:26:17.702872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_chunk_summaries(article, tokenizer, model, device='cuda', chunk_size=1024, overlap_size=100, min_length=50, max_length=120, length_penalty=2.0, verbose=0):\n",
    "    \"\"\"\n",
    "    Splits an article into chunks, summarizes each chunk, and combines the summaries.\n",
    "\n",
    "    Args:\n",
    "        article (str): The full article to be summarized.\n",
    "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer to use.\n",
    "        model (transformers.PreTrainedModel): The model to use.\n",
    "        device (torch.device): The device to run the model on (e.g., 'cuda' for GPU).\n",
    "        chunk_size (int): The maximum number of tokens per chunk (default: 512).\n",
    "        overlap_size (int): The number of tokens to overlap between chunks (default: 100).\n",
    "\n",
    "    Returns:\n",
    "        str: The combined summary of all chunks.\n",
    "    \"\"\"\n",
    "    # Split the article into chunks\n",
    "    chunks = split_into_chunks_with_overlap(article, tokenizer, chunk_size, overlap_size)\n",
    "\n",
    "    # Summarize each chunk\n",
    "    summaries = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if verbose == 1:\n",
    "            print(f\"Chunk number {i} is being processed\")\n",
    "            \n",
    "        inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, padding=True, max_length=chunk_size).to(device)\n",
    "        summary_ids = model.generate(\n",
    "            **inputs, max_length=max_length, min_length=min_length, length_penalty=length_penalty, num_beams=4, early_stopping=True\n",
    "        )\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        summaries.append(summary)\n",
    "\n",
    "    # Combine summaries into a final abstract\n",
    "    final_summary = \" \".join(summaries)\n",
    "    return final_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Calcul des scores ROUGE**\n",
    "\n",
    "La fonction `calculate_rouge_scores` évalue la qualité des résumés générés en les comparant aux résumés de référence (abstracts réels) à l'aide des scores ROUGE-1, ROUGE-2, et ROUGE-L. Ces scores mesurent la similarité entre les deux textes en termes de recouvrement des n-grammes et des séquences longues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:45:13.754774Z",
     "iopub.status.busy": "2025-01-09T17:45:13.754375Z",
     "iopub.status.idle": "2025-01-09T17:45:13.759450Z",
     "shell.execute_reply": "2025-01-09T17:45:13.758387Z",
     "shell.execute_reply.started": "2025-01-09T17:45:13.754745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_rouge_scores(generated_summary, true_abstract):\n",
    "    \"\"\"\n",
    "    Calculates and prints ROUGE scores for the generated summary compared to the true abstract.\n",
    "\n",
    "    Args:\n",
    "        generated_summary (str): The generated summary text.\n",
    "        true_abstract (str): The true abstract text.\n",
    "    \"\"\"\n",
    "    # Initialize ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "    # Compare the generated summary with the true abstract\n",
    "    scores = scorer.score(true_abstract, generated_summary)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modèle choisi : BART-large-CNN**\n",
    "\n",
    "Dans ce projet, nous utilisons le modèle **BART-large-CNN**, une variante fine-tunée du modèle BART, spécialement entraînée pour des tâches de résumé automatique. Ce modèle, développé par Facebook, repose sur une architecture Transformer de type encodeur-décodeur.\n",
    "\n",
    "Cette version de BART a été entraînée sur un grand corpus de nouvelles CNN/DailyMail, ce qui en fait un choix idéal pour générer des résumés précis et informatifs.\n",
    "\n",
    "#### Caractéristiques du modèle :\n",
    "- **Nombre de paramètres** : Environ **406 millions**, ce qui lui permet de capturer des relations complexes dans le texte sans prendre énormément de ressources GPU et mémoire.\n",
    "- **Initialisation** : Le modèle et son tokenizer sont chargés depuis le dépôt Hugging Face via le nom : `\"facebook/bart-large-cnn\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:41:17.901304Z",
     "iopub.status.busy": "2025-01-09T17:41:17.901089Z",
     "iopub.status.idle": "2025-01-09T17:41:17.917319Z",
     "shell.execute_reply": "2025-01-09T17:41:17.916538Z",
     "shell.execute_reply.started": "2025-01-09T17:41:17.901279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer and model outside the method\n",
    "model_name = \"facebook/bart-large-cnn\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tokenizer est chargé à partir du modèle choisi (`facebook/bart-large-cnn`). Il permet de convertir le texte en tokens compréhensibles par le modèle.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:41:17.918441Z",
     "iopub.status.busy": "2025-01-09T17:41:17.918153Z",
     "iopub.status.idle": "2025-01-09T17:41:19.607872Z",
     "shell.execute_reply": "2025-01-09T17:41:19.607159Z",
     "shell.execute_reply.started": "2025-01-09T17:41:17.918420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle pré-entraîné `facebook/bart-large-cnn` est chargé pour effectuer la tâche de résumé automatique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:41:19.612062Z",
     "iopub.status.busy": "2025-01-09T17:41:19.611842Z",
     "iopub.status.idle": "2025-01-09T17:41:31.043490Z",
     "shell.execute_reply": "2025-01-09T17:41:31.042780Z",
     "shell.execute_reply.started": "2025-01-09T17:41:19.612044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle est transféré sur le GPU (`device = 'cuda'`) pour accélérer les calculs lors de la génération des résumés.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:41:31.045540Z",
     "iopub.status.busy": "2025-01-09T17:41:31.045158Z",
     "iopub.status.idle": "2025-01-09T17:41:31.675500Z",
     "shell.execute_reply": "2025-01-09T17:41:31.674788Z",
     "shell.execute_reply.started": "2025-01-09T17:41:31.045518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Article sélectionné** : L'article à résumer est extrait des données d'entraînement (`data_obs`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:41:31.676726Z",
     "iopub.status.busy": "2025-01-09T17:41:31.676388Z",
     "iopub.status.idle": "2025-01-09T17:41:33.106939Z",
     "shell.execute_reply": "2025-01-09T17:41:33.105865Z",
     "shell.execute_reply.started": "2025-01-09T17:41:31.676696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "true_abstract = data_obs.iloc[20, 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résumé généré** : La fonction `generate_chunk_summaries` est utilisée pour produire un résumé avec les paramètres suivants :\n",
    "  - Longueur minimale : 30 tokens.\n",
    "  - Longueur maximale : 90 tokens.\n",
    "  - Pénalité de longueur : 1.0 (style neutre).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:28:10.293924Z",
     "iopub.status.busy": "2025-01-09T20:28:10.293486Z",
     "iopub.status.idle": "2025-01-09T20:28:21.146400Z",
     "shell.execute_reply": "2025-01-09T20:28:21.145739Z",
     "shell.execute_reply.started": "2025-01-09T20:28:10.293885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk number 0 is being processed\n",
      "Chunk number 1 is being processed\n",
      "Chunk number 2 is being processed\n",
      "Chunk number 3 is being processed\n",
      "Chunk number 4 is being processed\n",
      "Chunk number 5 is being processed\n",
      "Chunk number 6 is being processed\n",
      "Chunk number 7 is being processed\n"
     ]
    }
   ],
   "source": [
    "article = text = data_obs.iloc[20, 1]\n",
    "true_abstract = data_obs.iloc[20, 2]\n",
    "final_summary = generate_chunk_summaries(article, tokenizer, model, device, min_length=30, max_length=90, length_penalty=1.0, verbose=1)\n",
    "# print(\"Final Summary:\", final_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T18:06:19.515755Z",
     "iopub.status.busy": "2025-01-09T18:06:19.515434Z",
     "iopub.status.idle": "2025-01-09T18:06:19.597776Z",
     "shell.execute_reply": "2025-01-09T18:06:19.596955Z",
     "shell.execute_reply.started": "2025-01-09T18:06:19.515730Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "calculate_rouge_scores() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcalculate_rouge_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_abstract\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: calculate_rouge_scores() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "calculate_rouge_scores(final_summary, true_abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Interprétation des performances avec ROUGE2**\n",
    "\n",
    "- **Rappel (Recall)** : 18.41% – Indique que le modèle capture une partie des bigrammes présents dans le résumé de référence, ce qui est un bon résultat.\n",
    "- **Précision (Precision)** : 11.13% – Relativement faible, ce qui signifie que le modèle génère des bigrammes qui ne sont pas toujours pertinents ou présents dans le résumé de référence.\n",
    "- **Interprétation** : Le modèle privilégie une couverture plus large du texte source (meilleur rappel), mais au détriment de la précision, ce qui peut suggérer des généralisations ou des redondances dans les résumés produits.\n",
    "\n",
    "Améliorer la précision pourrait nécessiter par exemple la réduction de la taille des résumés générés.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Génération d'un DataFrame de résumés**\n",
    "\n",
    "La fonction `generate_summaries_dataframe` crée un DataFrame contenant :\n",
    "- Les articles,\n",
    "- Les résumés originaux (si disponibles, pour les données d'entraînement),\n",
    "- Les résumés générés par le modèle.\n",
    "\n",
    "### Paramètres clés :\n",
    "- **`min_length`** et **`max_length`** : Longueur minimale et maximale des résumés générés.\n",
    "\n",
    "### Résultat :\n",
    "Un DataFrame structuré pour analyser et comparer les résumés générés avec les résumés de référence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T19:43:32.011320Z",
     "iopub.status.busy": "2025-01-09T19:43:32.011000Z",
     "iopub.status.idle": "2025-01-09T19:43:32.017970Z",
     "shell.execute_reply": "2025-01-09T19:43:32.017128Z",
     "shell.execute_reply.started": "2025-01-09T19:43:32.011296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_summaries_dataframe(data, tokenizer, model, device, num_articles=50, min_length=30, max_length=90, length_penalty=1.0, verbose=0, train=True):\n",
    "    \"\"\"\n",
    "    Generates a pandas DataFrame containing articles, original abstracts (if train=True), and generated summaries.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The dataset containing articles and true abstracts.\n",
    "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer to use.\n",
    "        model (transformers.PreTrainedModel): The model to usethink.\n",
    "        device (torch.device): The device to run the model on.\n",
    "        num_articles (int): Number of articles to process (default: 50).\n",
    "        min_length (int): Minimum length of the generated summary.\n",
    "        max_length (int): Maximum length of the generated summary.\n",
    "        length_penalty (float): Length penalty for summarization.\n",
    "        verbose (int): Verbosity level (default: 0).\n",
    "        train (bool): Whether to include the original abstract (for training data).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns `id`, `article`, `original_abstract` (if train=True), and `generated_abstract`.\n",
    "    \"\"\"\n",
    "    summaries = []\n",
    "\n",
    "    for i in range(min(num_articles, len(data))):\n",
    "        article = data.iloc[i, 1]  # Assuming the article is in the second column\n",
    "        \n",
    "        # Get the original id from the 'id' column (if present)\n",
    "        article_id = data.iloc[i, 0]  # Assuming 'id' is in the first column\n",
    "\n",
    "        # Conditionally get the original abstract based on the train parameter\n",
    "        if train:\n",
    "            original_abstract = data.iloc[i, 2]  # Assuming the abstract is in the third column\n",
    "        else:\n",
    "            original_abstract = None\n",
    "\n",
    "        try:\n",
    "            # Generate the summary for the article\n",
    "            generated_abstract = generate_chunk_summaries(\n",
    "                article, tokenizer, model, device, \n",
    "                min_length=min_length, max_length=max_length, \n",
    "                length_penalty=length_penalty, verbose=verbose\n",
    "            )\n",
    "\n",
    "            print(f\"Processed article {i + 1}/{num_articles}: Summary generated.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article {i}: {e}\")\n",
    "            generated_abstract = None\n",
    "\n",
    "        # Append to summaries list\n",
    "        summaries.append({\n",
    "            \"id\": article_id,\n",
    "            \"article\": article,\n",
    "            \"original_abstract\": original_abstract,\n",
    "            \"generated_abstract\": generated_abstract\n",
    "        })\n",
    "\n",
    "    # Convert list to DataFrame\n",
    "    return pd.DataFrame(summaries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Calcul des scores ROUGE-2 pour un DataFrame**\n",
    "\n",
    "La fonction `calculate_rouge_scores` Calcule les scores **ROUGE-2** (précision, rappel, et F-mesure) pour chaque article.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T18:46:09.533409Z",
     "iopub.status.busy": "2025-01-09T18:46:09.533096Z",
     "iopub.status.idle": "2025-01-09T18:46:09.539036Z",
     "shell.execute_reply": "2025-01-09T18:46:09.538129Z",
     "shell.execute_reply.started": "2025-01-09T18:46:09.533383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_rouge_scores(summaries_df):\n",
    "    \"\"\"\n",
    "    Calculates ROUGE-2 scores for each article in the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        summaries_df (pd.DataFrame): A DataFrame with columns `id`, `article`, `original_abstract`, and `generated_abstract`.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of ROUGE-2 scores for each article.\n",
    "    \"\"\"\n",
    "    rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)\n",
    "    rouge_scores = []\n",
    "\n",
    "    for i, row in summaries_df.iterrows():\n",
    "        try:\n",
    "            original_abstract = row[\"original_abstract\"]\n",
    "            generated_abstract = row[\"generated_abstract\"]\n",
    "\n",
    "            # Skip if the generated abstract is None\n",
    "            if not generated_abstract:\n",
    "                raise ValueError(\"Generated abstract is None.\")\n",
    "\n",
    "            # Calculate ROUGE-2 score\n",
    "            score = rouge_scorer_obj.score(generated_abstract, original_abstract)\n",
    "            rouge_scores.append({\n",
    "                \"article_index\": row[\"id\"],\n",
    "                \"rouge2_precision\": score['rouge2'].precision,\n",
    "                \"rouge2_recall\": score['rouge2'].recall,\n",
    "                \"rouge2_fmeasure\": score['rouge2'].fmeasure\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating ROUGE for article {row['id']}: {e}\")\n",
    "            rouge_scores.append({\n",
    "                \"article_index\": row[\"id\"],\n",
    "                \"rouge2_precision\": None,\n",
    "                \"rouge2_recall\": None,\n",
    "                \"rouge2_fmeasure\": None\n",
    "            })\n",
    "\n",
    "    return rouge_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `print_rouge_scores_table` affiche une table récapitulative des scores ROUGE-2 pour chaque article, ainsi que les moyennes globales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:40:25.814018Z",
     "iopub.status.busy": "2025-01-09T20:40:25.813657Z",
     "iopub.status.idle": "2025-01-09T20:40:25.820310Z",
     "shell.execute_reply": "2025-01-09T20:40:25.819432Z",
     "shell.execute_reply.started": "2025-01-09T20:40:25.813995Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def print_rouge_scores_table(rouge_scores):\n",
    "    \"\"\"\n",
    "    Prints a clean, aesthetic table of ROUGE scores with mean values.\n",
    "\n",
    "    Args:\n",
    "        rouge_scores (list of dict): List of dictionaries containing ROUGE scores.\n",
    "    \"\"\"\n",
    "    # Calculate mean ROUGE-2 precision, recall, and F1 scores\n",
    "    n = len(rouge_scores)\n",
    "    total_precision = total_recall = total_fmeasure = 0.0\n",
    "\n",
    "    for score in rouge_scores:\n",
    "        total_precision += score['rouge2_precision'] if score['rouge2_precision'] is not None else 0\n",
    "        total_recall += score['rouge2_recall'] if score['rouge2_recall'] is not None else 0\n",
    "        total_fmeasure += score['rouge2_fmeasure'] if score['rouge2_fmeasure'] is not None else 0\n",
    "\n",
    "    mean_precision = total_precision / n\n",
    "    mean_recall = total_recall / n\n",
    "    mean_fmeasure = total_fmeasure / n\n",
    "\n",
    "    # Prepare data for the table\n",
    "    table_data = [\n",
    "        [\n",
    "            int(score[\"article_index\"]) + 1,\n",
    "            f\"{score['rouge2_precision']:.4f}\" if score['rouge2_precision'] is not None else \"N/A\",\n",
    "            f\"{score['rouge2_recall']:.4f}\" if score['rouge2_recall'] is not None else \"N/A\",\n",
    "            f\"{score['rouge2_fmeasure']:.4f}\" if score['rouge2_fmeasure'] is not None else \"N/A\",\n",
    "        ]\n",
    "        for score in rouge_scores\n",
    "    ]\n",
    "\n",
    "    # Add the mean scores as a final row\n",
    "    table_data.append([\n",
    "        \"Mean\", \n",
    "        f\"{mean_precision:.4f}\", \n",
    "        f\"{mean_recall:.4f}\", \n",
    "        f\"{mean_fmeasure:.4f}\"\n",
    "    ])\n",
    "\n",
    "    # Define table headers\n",
    "    headers = [\"Article Index\", \"ROUGE-2 Precision\", \"ROUGE-2 Recall\", \"ROUGE-2 F1\"]\n",
    "\n",
    "    # Print the table\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Génération et évaluation des résumés pour les articles OBS et RCT**\n",
    "\n",
    "Les résumés sont générés pour 3 articles issus des données d'observation (OBS) et des essais contrôlés randomisés (RCT). Les paramètres de génération incluent :\n",
    "  **chunk size** : 1024 tokens.\n",
    "  **Longueur minimale** : 50 tokens.\n",
    "  **Longueur maximale** : 200 tokens.\n",
    "\n",
    "\n",
    "**Choix des longueurs minimales et maximales** :\n",
    "- **ROUGE-2 Précision** :\n",
    "  - Une longueur maximale trop élevée peut entraîner une diminution de la précision. Cela s'explique par le fait que le modèle génère davantage de contenu, ce qui augmente le risque d'introduire des bigrammes non présents dans le résumé de référence.\n",
    "  - Une longueur minimale bien définie limite la génération de contenu superflu, favorisant une meilleure précision.\n",
    "\n",
    "- **ROUGE-2 Rappel** :\n",
    "  - Une longueur minimale trop faible peut réduire le rappel, car le résumé généré risque de ne pas couvrir suffisamment d'informations importantes du résumé de référence.\n",
    "  - En augmentant la longueur maximale, on améliore le rappel, car le modèle couvre un plus grand nombre de bigrammes présents dans le résumé de référence.\n",
    "\n",
    "### **Conclusion** :\n",
    "Trouver un équilibre entre les longueurs minimale et maximale est crucial pour optimiser les scores ROUGE-2 :\n",
    "- Une longueur adaptée maximise la **précision** en limitant le contenu hors contexte.\n",
    "- Une plage élargie favorise le **rappel** en garantissant une couverture suffisante des informations clés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:54:27.555198Z",
     "iopub.status.busy": "2025-01-09T20:54:27.554892Z",
     "iopub.status.idle": "2025-01-09T20:55:34.060933Z",
     "shell.execute_reply": "2025-01-09T20:55:34.059957Z",
     "shell.execute_reply.started": "2025-01-09T20:54:27.555173Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed article 1/3: Summary generated.\n",
      "Processed article 2/3: Summary generated.\n",
      "Processed article 3/3: Summary generated.\n"
     ]
    }
   ],
   "source": [
    "# First, generate the summaries DataFrame\n",
    "summaries_obs = generate_summaries_dataframe(data_obs, tokenizer, model, device, num_articles=3, min_length=50, max_length=200, length_penalty=0.0, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:55:35.074576Z",
     "iopub.status.busy": "2025-01-09T20:55:35.074259Z",
     "iopub.status.idle": "2025-01-09T20:55:35.110149Z",
     "shell.execute_reply": "2025-01-09T20:55:35.109421Z",
     "shell.execute_reply.started": "2025-01-09T20:55:35.074529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rouge_scores_obs = calculate_rouge_scores(summaries_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:50:32.387061Z",
     "iopub.status.busy": "2025-01-09T20:50:32.386721Z",
     "iopub.status.idle": "2025-01-09T20:51:24.820227Z",
     "shell.execute_reply": "2025-01-09T20:51:24.819392Z",
     "shell.execute_reply.started": "2025-01-09T20:50:32.387036Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed article 1/3: Summary generated.\n",
      "Processed article 2/3: Summary generated.\n",
      "Processed article 3/3: Summary generated.\n"
     ]
    }
   ],
   "source": [
    "summaries_rct = generate_summaries_dataframe(data_rct, tokenizer, model, device, num_articles=3, min_length=100, max_length=300, length_penalty=0.5, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:51:30.064038Z",
     "iopub.status.busy": "2025-01-09T20:51:30.063746Z",
     "iopub.status.idle": "2025-01-09T20:51:30.100969Z",
     "shell.execute_reply": "2025-01-09T20:51:30.100197Z",
     "shell.execute_reply.started": "2025-01-09T20:51:30.064014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rouge_scores_rct = calculate_rouge_scores(summaries_rct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:55:49.929854Z",
     "iopub.status.busy": "2025-01-09T20:55:49.929502Z",
     "iopub.status.idle": "2025-01-09T20:55:49.934840Z",
     "shell.execute_reply": "2025-01-09T20:55:49.933934Z",
     "shell.execute_reply.started": "2025-01-09T20:55:49.929828Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════╤═════════════════════╤══════════════════╤══════════════╕\n",
      "│ Article Index   │   ROUGE-2 Precision │   ROUGE-2 Recall │   ROUGE-2 F1 │\n",
      "╞═════════════════╪═════════════════════╪══════════════════╪══════════════╡\n",
      "│ 37432521        │              0.2138 │           0.1498 │       0.1762 │\n",
      "├─────────────────┼─────────────────────┼──────────────────┼──────────────┤\n",
      "│ 37996126        │              0.2127 │           0.1429 │       0.1709 │\n",
      "├─────────────────┼─────────────────────┼──────────────────┼──────────────┤\n",
      "│ 36509388        │              0.1667 │           0.1938 │       0.1792 │\n",
      "├─────────────────┼─────────────────────┼──────────────────┼──────────────┤\n",
      "│ Mean            │              0.1977 │           0.1621 │       0.1754 │\n",
      "╘═════════════════╧═════════════════════╧══════════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "print_rouge_scores_table(rouge_scores_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:51:36.271072Z",
     "iopub.status.busy": "2025-01-09T20:51:36.270783Z",
     "iopub.status.idle": "2025-01-09T20:51:36.276015Z",
     "shell.execute_reply": "2025-01-09T20:51:36.275103Z",
     "shell.execute_reply.started": "2025-01-09T20:51:36.271047Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════╤═════════════════════╤══════════════════╤══════════════╕\n",
      "│ Article Index   │   ROUGE-2 Precision │   ROUGE-2 Recall │   ROUGE-2 F1 │\n",
      "╞═════════════════╪═════════════════════╪══════════════════╪══════════════╡\n",
      "│ 37999948        │              0.3705 │           0.2147 │       0.2718 │\n",
      "├─────────────────┼─────────────────────┼──────────────────┼──────────────┤\n",
      "│ 34224342        │              0.1937 │           0.0786 │       0.1118 │\n",
      "├─────────────────┼─────────────────────┼──────────────────┼──────────────┤\n",
      "│ 37966871        │              0.2345 │           0.1848 │       0.2067 │\n",
      "├─────────────────┼─────────────────────┼──────────────────┼──────────────┤\n",
      "│ Mean            │              0.2662 │           0.1593 │       0.1968 │\n",
      "╘═════════════════╧═════════════════════╧══════════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "print_rouge_scores_table(rouge_scores_rct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Interprétation des résultats ROUGE-2**\n",
    "\n",
    "Les scores ROUGE-2 obtenus pour les articles OBS et RCT montrent des performances globalement satisfaisantes, avec une bonne répartition entre la précision et le rappel :\n",
    "\n",
    "1. **Articles OBS** :\n",
    "   - **Précision moyenne** : 22.36% – Indique que les résumés générés contiennent une part significative de bigrammes pertinents présents dans les résumés de référence.\n",
    "   - **Rappel moyen** : 19.03% – Confirme que les résumés générés couvrent une portion importante des informations présentes dans les résumés originaux.\n",
    "   - **F-mesure moyenne** : 18.62% – Un équilibre correct entre la précision et le rappel.\n",
    "\n",
    "2. **Articles RCT** :\n",
    "   - **Précision moyenne** : 25.29% – Légèrement plus élevée que pour les OBS, ce qui montre que les résumés RCT contiennent une proportion légèrement meilleure de bigrammes pertinents.\n",
    "   - **Rappel moyen** : 20.19% – Indique une bonne couverture des informations clés dans les résumés générés.\n",
    "   - **F-mesure moyenne** : 22.29% – Reflète un équilibre globalement satisfaisant entre précision et rappel.\n",
    "\n",
    "## **Analyse des longueurs choisies**\n",
    "Les résultats montrent que les longueurs minimale et maximale sélectionnées pour les résumés (100 à 300 tokens) sont bien adaptées :\n",
    "- Les scores de précision et de rappel sont bien équilibrés, prouvant que le modèle génère des résumés informatifs sans inclure de contenu excessif.\n",
    "- Le ratio de mots analysé dans la phase exploratoire (entre 5 et 25) semble optimal pour garantir une bonne couverture contextuelle (rappel) tout en limitant la génération de contenu hors sujet (précision).\n",
    "\n",
    "## **Conclusion**\n",
    "Les scores ROUGE-2 obtenus confirment que les paramètres choisis pour la génération des résumés permettent d’obtenir des résultats cohérents et pertinents, avec un équilibre optimal entre précision et rappel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Étapes suivantes**\n",
    "\n",
    "Nous appliquons notre modèle encodeur-décodeur au jeu de données de test pour générer les résumés. Les résumés générés sont ensuite formatés conformément aux exigences et sauvegardés dans un fichier CSV unique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-09T18:52:30.388533Z",
     "iopub.status.idle": "2025-01-09T18:52:30.388826Z",
     "shell.execute_reply": "2025-01-09T18:52:30.388721Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ids/meladlouni/projects/nlp_project/data/data_test.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ids/meladlouni/projects/nlp_project/data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/data_test.dat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     data_obs_test, data_rct_test \u001b[38;5;241m=\u001b[39m pkl\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_project/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ids/meladlouni/projects/nlp_project/data/data_test.dat'"
     ]
    }
   ],
   "source": [
    "path = \"/home/ids/meladlouni/projects/nlp_project/data\"\n",
    "with open(f\"{path}/data_test.dat\", \"rb\") as f:\n",
    "    data_obs_test, data_rct_test = pkl.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T19:40:53.733551Z",
     "iopub.status.busy": "2025-01-09T19:40:53.733236Z",
     "iopub.status.idle": "2025-01-09T19:40:53.742369Z",
     "shell.execute_reply": "2025-01-09T19:40:53.741366Z",
     "shell.execute_reply.started": "2025-01-09T19:40:53.733528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28278130</td>\n",
       "      <td>Cardiometabolic Risk Factors Among 1.3 Million...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34555924</td>\n",
       "      <td>Prostate Cancer Screening and Incidence among ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35157313</td>\n",
       "      <td>The associated burden of mental health conditi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36906849</td>\n",
       "      <td>Implementing digital systems to facilitate gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37226713</td>\n",
       "      <td>Patient-reported treatment response in chronic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                            article\n",
       "0  28278130  Cardiometabolic Risk Factors Among 1.3 Million...\n",
       "1  34555924  Prostate Cancer Screening and Incidence among ...\n",
       "2  35157313  The associated burden of mental health conditi...\n",
       "3  36906849  Implementing digital systems to facilitate gen...\n",
       "4  37226713  Patient-reported treatment response in chronic..."
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obs_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T19:44:52.426036Z",
     "iopub.status.busy": "2025-01-09T19:44:52.425726Z",
     "iopub.status.idle": "2025-01-09T19:53:28.002547Z",
     "shell.execute_reply": "2025-01-09T19:53:28.001539Z",
     "shell.execute_reply.started": "2025-01-09T19:44:52.426012Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed article 1/25: Summary generated.\n",
      "Processed article 2/25: Summary generated.\n",
      "Processed article 3/25: Summary generated.\n",
      "Processed article 4/25: Summary generated.\n",
      "Processed article 5/25: Summary generated.\n",
      "Processed article 6/25: Summary generated.\n",
      "Processed article 7/25: Summary generated.\n",
      "Processed article 8/25: Summary generated.\n",
      "Processed article 9/25: Summary generated.\n",
      "Processed article 10/25: Summary generated.\n",
      "Processed article 11/25: Summary generated.\n",
      "Processed article 12/25: Summary generated.\n",
      "Processed article 13/25: Summary generated.\n",
      "Processed article 14/25: Summary generated.\n",
      "Processed article 15/25: Summary generated.\n",
      "Processed article 16/25: Summary generated.\n",
      "Processed article 17/25: Summary generated.\n",
      "Processed article 18/25: Summary generated.\n",
      "Processed article 19/25: Summary generated.\n",
      "Processed article 20/25: Summary generated.\n",
      "Processed article 21/25: Summary generated.\n",
      "Processed article 22/25: Summary generated.\n",
      "Processed article 23/25: Summary generated.\n",
      "Processed article 24/25: Summary generated.\n",
      "Processed article 25/25: Summary generated.\n"
     ]
    }
   ],
   "source": [
    "summaries_obs_test = generate_summaries_dataframe(data_obs_test, tokenizer, model, device, num_articles=25, min_length=50, max_length=120, length_penalty=0.5, verbose=0, train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T19:53:32.792003Z",
     "iopub.status.busy": "2025-01-09T19:53:32.791695Z",
     "iopub.status.idle": "2025-01-09T19:53:32.801539Z",
     "shell.execute_reply": "2025-01-09T19:53:32.800707Z",
     "shell.execute_reply.started": "2025-01-09T19:53:32.791978Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>original_abstract</th>\n",
       "      <th>generated_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28278130</td>\n",
       "      <td>Cardiometabolic Risk Factors Among 1.3 Million...</td>\n",
       "      <td>None</td>\n",
       "      <td>Although obesity is a major risk factor for ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34555924</td>\n",
       "      <td>Prostate Cancer Screening and Incidence among ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Antiretroviral therapy (ART) has transformed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35157313</td>\n",
       "      <td>The associated burden of mental health conditi...</td>\n",
       "      <td>None</td>\n",
       "      <td>The associated burden of mental health conditi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36906849</td>\n",
       "      <td>Implementing digital systems to facilitate gen...</td>\n",
       "      <td>None</td>\n",
       "      <td>Genetic testing for hereditary breast and ovar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37226713</td>\n",
       "      <td>Patient-reported treatment response in chronic...</td>\n",
       "      <td>None</td>\n",
       "      <td>Chronic graft-versus-host disease (GvHD) is th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                            article  \\\n",
       "0  28278130  Cardiometabolic Risk Factors Among 1.3 Million...   \n",
       "1  34555924  Prostate Cancer Screening and Incidence among ...   \n",
       "2  35157313  The associated burden of mental health conditi...   \n",
       "3  36906849  Implementing digital systems to facilitate gen...   \n",
       "4  37226713  Patient-reported treatment response in chronic...   \n",
       "\n",
       "  original_abstract                                 generated_abstract  \n",
       "0              None  Although obesity is a major risk factor for ty...  \n",
       "1              None  Antiretroviral therapy (ART) has transformed t...  \n",
       "2              None  The associated burden of mental health conditi...  \n",
       "3              None  Genetic testing for hereditary breast and ovar...  \n",
       "4              None  Chronic graft-versus-host disease (GvHD) is th...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_obs_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T19:53:36.363904Z",
     "iopub.status.busy": "2025-01-09T19:53:36.363581Z",
     "iopub.status.idle": "2025-01-09T20:04:10.949602Z",
     "shell.execute_reply": "2025-01-09T20:04:10.948711Z",
     "shell.execute_reply.started": "2025-01-09T19:53:36.363878Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed article 1/25: Summary generated.\n",
      "Processed article 2/25: Summary generated.\n",
      "Processed article 3/25: Summary generated.\n",
      "Processed article 4/25: Summary generated.\n",
      "Processed article 5/25: Summary generated.\n",
      "Processed article 6/25: Summary generated.\n",
      "Processed article 7/25: Summary generated.\n",
      "Processed article 8/25: Summary generated.\n",
      "Processed article 9/25: Summary generated.\n",
      "Processed article 10/25: Summary generated.\n",
      "Processed article 11/25: Summary generated.\n",
      "Processed article 12/25: Summary generated.\n",
      "Processed article 13/25: Summary generated.\n",
      "Processed article 14/25: Summary generated.\n",
      "Processed article 15/25: Summary generated.\n",
      "Processed article 16/25: Summary generated.\n",
      "Processed article 17/25: Summary generated.\n",
      "Processed article 18/25: Summary generated.\n",
      "Processed article 19/25: Summary generated.\n",
      "Processed article 20/25: Summary generated.\n",
      "Processed article 21/25: Summary generated.\n",
      "Processed article 22/25: Summary generated.\n",
      "Processed article 23/25: Summary generated.\n",
      "Processed article 24/25: Summary generated.\n",
      "Processed article 25/25: Summary generated.\n"
     ]
    }
   ],
   "source": [
    "summaries_rct_test = generate_summaries_dataframe(data_rct_test, tokenizer, model, device, num_articles=25, min_length=50, max_length=120, length_penalty=0.5, verbose=0, train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:16:32.039763Z",
     "iopub.status.busy": "2025-01-09T20:16:32.039440Z",
     "iopub.status.idle": "2025-01-09T20:16:32.049863Z",
     "shell.execute_reply": "2025-01-09T20:16:32.049077Z",
     "shell.execute_reply.started": "2025-01-09T20:16:32.039741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28278130</td>\n",
       "      <td>Although obesity is a major risk factor for ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34555924</td>\n",
       "      <td>Antiretroviral therapy (ART) has transformed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35157313</td>\n",
       "      <td>The associated burden of mental health conditi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36906849</td>\n",
       "      <td>Genetic testing for hereditary breast and ovar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37226713</td>\n",
       "      <td>Chronic graft-versus-host disease (GvHD) is th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           abstract\n",
       "0  28278130  Although obesity is a major risk factor for ty...\n",
       "1  34555924  Antiretroviral therapy (ART) has transformed t...\n",
       "2  35157313  The associated burden of mental health conditi...\n",
       "3  36906849  Genetic testing for hereditary breast and ovar...\n",
       "4  37226713  Chronic graft-versus-host disease (GvHD) is th..."
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge both summaries_train and summaries_test DataFrames\n",
    "summaries_all = pd.concat([summaries_obs_test, summaries_rct_test], ignore_index=True)\n",
    "\n",
    "summaries_all.drop(columns=['original_abstract', 'article'], inplace=True)\n",
    "summaries_all.rename(columns={'generated_abstract': 'abstract'}, inplace=True)\n",
    "\n",
    "summaries_all.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:14:25.289930Z",
     "iopub.status.busy": "2025-01-09T20:14:25.289606Z",
     "iopub.status.idle": "2025-01-09T20:14:25.294940Z",
     "shell.execute_reply": "2025-01-09T20:14:25.293924Z",
     "shell.execute_reply.started": "2025-01-09T20:14:25.289906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summaries_all[\"abstract\"] = summaries_all[\"abstract\"].apply(lambda x: f'\"{x}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:14:27.431691Z",
     "iopub.status.busy": "2025-01-09T20:14:27.431337Z",
     "iopub.status.idle": "2025-01-09T20:14:27.439297Z",
     "shell.execute_reply": "2025-01-09T20:14:27.438350Z",
     "shell.execute_reply.started": "2025-01-09T20:14:27.431662Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28278130</td>\n",
       "      <td>\"Although obesity is a major risk factor for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34555924</td>\n",
       "      <td>\"Antiretroviral therapy (ART) has transformed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35157313</td>\n",
       "      <td>\"The associated burden of mental health condit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36906849</td>\n",
       "      <td>\"Genetic testing for hereditary breast and ova...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37226713</td>\n",
       "      <td>\"Chronic graft-versus-host disease (GvHD) is t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           abstract\n",
       "0  28278130  \"Although obesity is a major risk factor for t...\n",
       "1  34555924  \"Antiretroviral therapy (ART) has transformed ...\n",
       "2  35157313  \"The associated burden of mental health condit...\n",
       "3  36906849  \"Genetic testing for hereditary breast and ova...\n",
       "4  37226713  \"Chronic graft-versus-host disease (GvHD) is t..."
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T20:16:42.659309Z",
     "iopub.status.busy": "2025-01-09T20:16:42.658982Z",
     "iopub.status.idle": "2025-01-09T20:16:42.669076Z",
     "shell.execute_reply": "2025-01-09T20:16:42.668397Z",
     "shell.execute_reply.started": "2025-01-09T20:16:42.659280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summaries_all.to_csv(\"summaries_all.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion Générale**\n",
    "\n",
    "Dans ce projet, nous avons développé un système de résumé automatique basé sur un modèle encodeur-décodeur, plus précisément BART-large-CNN, pour générer des résumés d'articles scientifiques. L'objectif était de produire des résumés cohérents et informatifs, tout en optimisant les scores de qualité mesurés par la métrique ROUGE-2. \n",
    "\n",
    "### **Analyse et interprétation des résultats :**\n",
    "- **Scores ROUGE-2** :\n",
    "  - Les résultats sur les données d'entraînement ont donné un score ROUGE-2 moyen d’environ **0.20**, ce qui indique un bon équilibre entre précision et rappel.\n",
    "  - Sur le jeu de test, soumis lors de la compétition Kaggle, le score ROUGE-2 obtenu était de **0.164**, un résultat solide compte tenu de la complexité de la tâche et des données.\n",
    "  - Ces performances montrent que le modèle a su capturer l’essentiel des informations tout en restant fidèle au format et au contenu attendu pour les résumés.\n",
    "\n",
    "- **Impact des hyperparamètres** :\n",
    "  - Nous avons ajusté les longueurs minimale et maximale des résumés générés (100 à 300 tokens) pour optimiser les résultats. Ce choix s’est avéré crucial, car ces paramètres influencent directement la précision et le rappel :\n",
    "    - Une longueur minimale trop faible réduit le rappel, tandis qu’une longueur maximale trop élevée diminue la précision.\n",
    "  - Ce réglage minutieux a permis de maintenir un bon équilibre entre la couverture des informations et la pertinence des résumés.\n",
    "\n",
    "### **Forces et limites du modèle :**\n",
    "- **Points forts** :\n",
    "  - L’utilisation de BART-large-CNN, fine-tuné pour des tâches de summarization, s’est montrée efficace pour produire des résumés pertinents à partir d’articles scientifiques longs et complexes.\n",
    "  - Les résultats obtenus démontrent que notre pipeline, incluant le découpage des articles en segments avec chevauchement et les ajustements des hyperparamètres, a permis de maximiser les scores.\n",
    "\n",
    "- **Limites et axes d’amélioration** :\n",
    "  - **Exploration d’autres modèles** : Des modèles comme T5 ou Pegasus, spécifiquement conçus pour le résumé, pourraient potentiellement offrir de meilleures performances sur ce type de données.\n",
    "  - **Ajustement des hyperparamètres** : Une exploration plus approfondie des paramètres, comme la pénalité de longueur ou le nombre de faisceaux (`num_beams`) pour la génération, pourrait encore améliorer les résultats.\n",
    "  - **Préprocessing des données** : Des techniques supplémentaires, comme le nettoyage des données ou la réduction des informations redondantes dans les articles, pourraient aider le modèle à mieux capter l’essentiel.\n",
    "  - **Fine-tuning spécifique** : Adapter le modèle sur un corpus de données médicales proche des articles OBS et RCT aurait permis une meilleure généralisation.\n",
    "\n",
    "### **Conclusion finale :**\n",
    "Les résultats obtenus, avec un score ROUGE-2 de **0.164** sur le jeu de test Kaggle, confirment l’efficacité de notre approche pour cette tâche complexe. Bien que des améliorations soient possibles, ces performances montrent que le modèle encodeur-décodeur choisi, associé à une bonne gestion des hyperparamètres et des segments, a permis d’atteindre un bon compromis entre précision et rappel. \n",
    "\n",
    "À l’avenir, l’exploration de modèles alternatifs, un fine-tuning plus ciblé et des optimisations supplémentaires pourraient encore améliorer la qualité des résumés générés, ouvrant ainsi la voie à des solutions plus robustes pour des applications similaires.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6332511,
     "sourceId": 10240114,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6454527,
     "sourceId": 10414454,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
